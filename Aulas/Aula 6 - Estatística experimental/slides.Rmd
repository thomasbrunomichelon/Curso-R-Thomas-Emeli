---
title: "Estatistica experimental"
author: "Thomas Bruno Michelon"
e-mail: "thomasbrunomichelon@gmail.com"
output:
  ioslides_presentation:
    css: ../../style.css
    logo: ../../curso-agro-r-logo.png
    smaller: yes
    widescreen: yes
  slidy_presentation: default
subtitle: Curso R para agronomia
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(paged.print=FALSE)
knitr::opts_chunk$set(echo=TRUE)
knitr::opts_chunk$set(error=FALSE)
knitr::opts_chunk$set(message=FALSE)
knitr::opts_chunk$set(warning=FALSE)
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

# Delineamento

## Delineamento Inteiramente Casualizado (DIC)

**Delineamento** é o controle do pesquisador sobre o experimento. Quando um local é homogêneo, não é necessário controlar onde serão colocadas as repetições e tratamentos, esses, podem *apenas* serem distribuidos aleatóriamento no local. Isso é im DIC.

O modelo matemático que determina o valor de cada observação é:

![](images/dic.png){width="911"}

$*$ **Importante:** como vamos estimar a média de cada tratamento, é importante que os erros sejam **normais**, ou seja, estejam distribuidos de forma igual entorno da média do tratamento.

## Delineamento Inteiramente Casualizado (DIC)

Como supomos que os erros são normalmente distriuidos, podemos estimar a média de cada tratamento usando a média geral e o efeito do tratamento:

$$
\mu_j=\mu+T_j
$$

$*$ **Importante!** Ao invés do R utilizar essa fórmula para estimar a média. O R utiliza ela de forma simplificada, sem a média geral:

$$
 \mu_j=T_j
$$

Dessa maneira, **o primeiro nível é usado como base o efeito dos demais níveis são somados a ele.** Apesar de ser diferente, o resultado é o mesmo.

## Exemplo

Veja esse exemplo de um experimento com consumo de 5 doses de farinha (0, 5, 10,15), onde foi medido o índice glicemico em animais.

```{r, echo = F, out.width="50%"}
library(ExpDes.pt);library(ggplot2)
dados <- ex1 # carregar os dados (ex1) armazenar em "dados"
dados$trat <- as.factor(dados$trat)
p <- ggplot(data=dados, aes(trat, ig,))+geom_point()
p <- p + geom_hline(aes(yintercept = mean(ig)))
p + stat_summary(fun = "mean", colour = "red", size = 6, geom = "point") + theme_classic(base_size = 20) + labs(x="tratamento", y="índice glicemico")
```

A média geral (linha horizontal) é: $97.2$, esse é nosso $\mu$. Já a média **por** tratamento (ponto vermelho), é: dose 0 = $102.2$; dose 5 = $95.1$; dose 10 = $96.7$; dose 15 = $94.7$. Ou seja, dependendo do tratamento, a média dele é maior ou menor que nossa média geral, o quanto maior ou menor é o nosso **efeito do tratamento** ($T_j$). Por exemplo: o efeito da dose 0 é aumentar $5$ unidades da média geral ($97.2 - 102.2$).

## Exemplos no R - DIC fatorial simples

### $1^{\circ}$ Carregando os dados

```{r}
library(ExpDes.pt) # carregar o pacote que tem os dados de exemplo (ex1)
dados <- ex1 # carregar ex1 armazenar em "dados"
dados$trat <- as.factor(dados$trat) # Entender que "trat" é um fator e não números
head(dados) # mostrar só o começo (head) dados
```

## Exemplos no R - DIC fatorial simples

### $2^{\circ}$ Criando o modelo

$$
lm(formula, data,...)
$$

-   **lm()** significa *linear models* e nela podemos inserir a **fórmula** do DIC: **Resposta\~Tratamento** ($\mu_j=T_j$).

-   **data** é o objeto com os dados.

$*$ **Cuidado com a terminologia!** Linear models, significa modelo linear e significa que os coeficientes da fórmula são lineares entre eles e não que a relação entre a resposta e o tratamento é necesariamente linear (uma linha reta).

## Exemplos no R - DIC fatorial simples

### $2^{\circ}$ Criando o modelo

```{r}
lm(ig~trat, data = dados) # criando modelo
```

Repare, $102.198$ ("intercept") é a média da dose 0, ele foi utilizado como "base", trat5 é a diferença entre a média da dose 0 e a média da dose 5, ou seja, $95.058 - 102.198 = -7.140$.

## DIC fatorial duplo

Quando temos mais tratamentos na nossa pesquisa, devemos inserir não só o efeito desses tratamentos, mas também o efeito da interação:

$$
 \mu_{jh}=\mu+T_j+T_h+T_J*T_h
$$ A média ($\mu$) no nível $j$ do seu primeiro tratamento e no nível $h$ do seu segundo tratamento é igual a média geral somada aos **efeitos simples** dos tratamentos, assim como o **efeito da interação** deles.

## Exemplos no R - DIC fatorial duplo

### $1^{\circ}$ Carregando os dados

Experimento em campo para testar a compostagem de casca de café misturada ou não com esterco bovinos (variável esterco) em diferentes intervalos de revolvimento (variável revol).

```{r}
library(ExpDes.pt) # carregar o pacote que tem os dados de exemplo (ex4)
dados <- ex4 # armazenar ex4 em "dados"
dados$revol <- as.factor(dados$revol) # entender que "trat" é um fator e não números
head(dados) # mostrar o começo dos dados
```

## Exemplos no R - DIC fatorial duplo

### $2^{\circ}$ Criando o modelo:

No R, a notação é **Resposta\~Tratamento1+Tratamento2+Tratamento1**$\colon$**Tratamento2** ou por sua forma abreviada: **Resposta\~Tratamento1\*Tratamento2**.

```{r}
lm(c~revol*esterco, data=dados) # criando modelo
```

Repare que no fatorial duplo, foi utilizada a média da resposta no intervalo de revolvimento 5 (primeiro nível do tratamento 1) com a presença de esterco (primeiro nível do tratamento 2). É o valor 19.6667 indicado no "intercept" e os demais valores são a diferença em relação ao "intercept".

## Demais fatoriais

Para um fatorial triplo ou qualquer que seja a quantidade de tratamentos que possui, basta utilizar a mesma notação anterior, apenas acrescentando "\*" e o novo tratamento:

$$
Resposta\sim Tratamento1*Tratamento2*Tratamento3…
$$

## Delineamento em Blocos Casualizados (DBC)

Nesse delineamento é feito o controle da área experimental, pois, essa é heterogênea. Então se subdivide a área em blocos, os quais são homogeneos dentro deles e então podemos distribuir nossos tratamentos em cada bloco:$$
\mu_{ij}=\mu+bloco_i+T_j
$$

Ou seja, a média de um dos níveis ($j$) do seu tratamento, em um dos blocos ($i$), vai ser igual à média geral ($\mu$) somado aos efeitos do tratamento ($T_j$) e do bloco.

## Exemplos no R - DBC Fatorial simples

### $1^{\circ}$ Carregando os dados

Dados do livro Pimentel-Gomes da produção ($t. ha^{-1}$) de oito variedades de batatinha em DBC (quatro blocos).

```{r}
# lendo dados do repositório online
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/Pimentel%20gomes%20DBC")
head(dados) # mostrando o começo dos dados
```

## Exemplos no R - DBC Fatorial simples

### $2^{\circ}$ Criando modelo

A notação do DBC é: **Resposta\~Bloco+Tratamento**.

```{r}
lm(producao~bloco+variedade, data=dados) # modelo DBC
```

## Demais delineamentos

Para os demais delineamentos, basta saber qual é o modelo e inserí-lo na função **lm()**:

-   Quadrado latino: **Resposta\~linha+coluna+tratamento**

-   Tratamento adicional: **Resposta\~Tratamento adicional+Tratamento\***

    -   Para o tratamento adicional, é necessário criar uma nova variável e atribuir um valor para o tratamento adicional e outro valor para os demais tratamentos. Ex.: uma coluna com "a" para o tratamento adicional e "b" para os demais.

Para delineamentos com efeitos fixos e aleatórios (como no caso de parcelas subdividadas), deve-se utilizar a função **aov()**.

-   Parcela subdividida em DIC: **Resposta\~Fator1\*Fator2+Erro(Fator1:repetição)**

-   Parcela subdividida em DBC: **Resposta\~Bloco+Fator1\*Fator2+Erro(bloco/Fator1)**

# ANOVA

## Porque a ANOVA?

Se quisermos testar um tratamento com dois níveis A e B, basta fazer um teste T para as médias. Porém, se temos um tratamento com mais níveis A, B e C, já teriamos três testes: AB, AC e BC. Quanto mais testes, maior a chance de errarmos, visto que os testes têm uma "probabilidade de acerto".

Uma alternativa é testar ao invés da média, as variâncias das médias: **variância entre os níveis vs variância dentro de cada nível.**

![](images/anova.png){width="658"}

Assim, independente do número de níveis, estariamos fazendo apenas um teste e testando "todas as médias de uma vez".

## Pressupostos

Os pressupostos que devemos checar para análise de variância são em relação ao resíduo (ou erros), ou seja, **a diferença entre o que foi medido e o estimados pelo modelo.**

O erros devem:

-   **Ser independentes**: os erros não devem apresentar correlação entre si.
-   **Ter variância homogênea (homocedásticos)**: todos os erros variam de forma igual.
-   **Ser normais**: erros possuem distribuição normal com média igual a zero.

## Exemplos no R - Testes dos pressupostos

### Obtendo os erros

$$
residuals(modelo,...)
$$

Os testes são aplicados aos erros. Dessa forma, devemos primeiro ajustar o modelo, encontrar o erro e aí aplicar os testes:

```{r}
library(ExpDes.pt) # carregar pacote
dados <- ex1 # armazenar ex1 em "dados"
dados$trat <- as.factor(dados$trat) # transformar 
modelo <- lm(ig~trat, data=dados) # entender que "trat" é um fator e não números
erros <- residuals(modelo) # função "residuals" para obter os erros
```

## Exemplos no R - Testes dos pressupostos

### Normalidade dos resíduos: teste de Shapiro-Wilk:

$$
shapiro.test(object,...)
$$

```{r}
shapiro.test(erros) # teste de Shapiro-Wilk
```

## Exemplos no R - Testes dos pressupostos

### Homogeneidade das variâncias dos resíduos: teste de Levene

$$
leveneTest(object, data,...)
$$

```{r}
library(car) # pacote com a função
leveneTest(erros~trat, data=dados) # teste de Levene
```

## Exemplos no R - Testes dos pressupostos

### Homogeneidade das variâncias dos resíduos: teste de Bartlett

$$
bartlett.test(object, data,...)
$$

```{r}
bartlett.test(erros~trat, data=dados) # teste de Bartlett
```

## Exemplos no R - Testes dos pressupostos

### Independência dos resíduos: teste de Durbin-Watson

$$
durbinWatsonTest(model,...)
$$

```{r}
library(car) # pacote com a função
durbinWatsonTest(modelo) # teste de Durbin-Watson
```

## Análise gráfica dos pressupostos

$$
plot(modelo,...)
$$

Se usarmos a função **plot()** em um modelo que criamos com a função **lm()**, são gerados quatro gráficos para análise dos resíduos.

1.  **Resíduos vs valores ajustados:** é o erro que obtivemos em cada observação com o modelo que ajustamos. Devemos observar duas coisas, (1) se a média dos resíduos em cada tratamento está próxima de zero e (2) se a variância dos resíduos em cada tratamento é constante.

2.  **Resíduos padronizados vs valores ajustados:** a escala dos nossos dados pode dificultar a visualização, assim, o gráfico é semelhante ao anterior, porém, com a escala padronizada.

3.  **Quantil-quantil normal:** quantil é basicamente ordenar seus dados de forma crescente e observar como eles se distribuem. Quantil-quantil normal é você comparar a distribuição deles com a distribuição normal, que é a que esperamos que nossos resíduos tenham.

4.  **Constant Leverage:** *leverage* é "quanto meu dado influencia no meu modelo". Como estamos medindo a distância (erro) de cada observção em relação ao nosso modelo, podemos ver o quanto esse único erro influencia todo nosso modelo. É uma forma de indentificarmos possíveis outliers.

## Análise gráfica dos pressupostos

### Resíduos vs Valores ajustados

![](images/analise_grafica_1.png){width="780"}

## Análise gráfica dos pressupostos

### Quantil-quantil normal

![](images/analise_grafica_3.png){width="719"}

## Análise gráfica dos pressupostos

### Constant Leverage

![](images/analise_grafica_4.png){width="653"}

## Exemplos no R - Análise dos pressupostos

```{r, out.width="60%"}
modelo <- lm(ig~trat, data=dados) # criando modelo
par(mfrow=c(2,2)) # plotar os quatro gráficos na mesma tela
plot(modelo) # gerar gráficos 
```

## Transformações

Se seus dados não são normais, você pode transformá-los. Porém, existem diversas fórmulas e transformações. Por exemplo, podemos simplesmente elevar nossos dados: $resposta^2$ ou realizar o logarítimo: $log(resposta)$.

![](images/trasnformacao.png){width="416"}

Então, a pergunta que fica é: **qual transformação utilizar?**

## Box-Cox

Box-Cox é um **família** de transformações, ou seja, em sua fórmula, podemos tranformar nossos dados de diferentes formas **conforme um critério**. O critério é a escolha de uma váriável chamada $\lambda$.

1.  Quando escolhemos algum valor de $\lambda \neq 0$, os dados ($y$) são transformados da a seguinte forma:

$$
y_i'= (y_i^\lambda-1)/\lambda
$$

2.  Quando escolhemos $\lambda=0$, é feito apenas o $log(y)$, na base $e$.

Então basta: (1) escolhermos vários valores para lambda, (2) transformar nossos dados e (3) ver qual a melhor transformação.

## Exemplos no R - Box-Cox

```{r, echo=F}
library(ExpDes.pt) # carrear pacote
dados <- ex1 # armazenar ex1 em "dados"
dados$trat <- as.factor(dados$trat) # entender que "trat" é um fator e não números
```

Podemos testar vários lambdas e avaliar o ajuste automaticamente pela função do pacote **MASS**:

$$
boxcox(object,...)
$$

-   **Object:** é a disposição ou delineamento dos seus dados no formato de **fórmula**.
    -   Se seus modelo estão dispostos como $resposta \sim tratamento_1 * tratamento_2$, é assim que deverá ser especificado no objeto.

## Exemplos no R - Box-Cox

### $1^{\circ}$ Identificando o melhor lambda

```{r, eval=FALSE, out.width="70%"}
library(MASS) # carregando o pacote com a função "boxcox"
bc <- boxcox(dados$ig~dados$trat) # testando os lambdas e identificando o melhor
```

## Exemplos no R - Box-Cox

```{r, echo=FALSE, out.width="70%"}
library(MASS) # carregando o pacote com a função "boxcox"
bc <- boxcox(dados$ig~dados$trat) # testando os lambdas e identificando o melhor
```

Repare que o maior valor de *log-likelihood* gerado no gráfico é quando $\lambda$ é quase 0.

## Exemplos no R - Box-Cox

### $2^{\circ}$ Extraindo o lambda

Para criar o gráfico, a função gerou duas colunas de dados, uma com os diferentes lambdas testados (coluna x) e outra com a medida de ajuste de cada um, chamado de *log-likelihood* (coluna y).

Como armazenamos esses dados em "bc", podemos encontrar o valor do melhor ajuste e o seu lambda.

```{r}
maior_likelihood <- which.max(bc$y) # maior valor do "log likelihood"
lambda <- bc$x[maior_likelihood] # valor do lambda que corresponde ao maior "log likelihood"
lambda # valor de lambda
```

Nosso lambda é $0.02$ aproximadamente. Ou seja, nossos dados transformados ficariam: $y'=y^{0.02}-1/0.02$.

## Exemplos no R - Box-Cox

### $3^{\circ}$ Transformando todos os dados e usado no modelo

```{r}
bc <- function(y, lambda) { # criando uma função
      if (lambda == 0L) { # se o lambda for igual a 0, log(y)
      log(y)
      } else { # se for diferente de 0, (y^lambda)-1/lambda
      ((y^lambda) - 1) / lambda
      }
  }
dados_transformados <- bc(dados$ig, 0.0202) # transformando
head(cbind(dados$ig, dados_transformados)) # mostrando os dados lado a lado (cbind)
```

## Exemplos no R - Box-Cox

### $4^{\circ}$ Usando seus dados transformados no modelo

```{r}
lm(dados_transformados~trat, data=dados) # modelo com os dados transformados
```

$*$ Repare que os dados ficam na nova escala e assim também ficarão quando fizer a comparação de médias.

## ANOVA

$$
anova(object,...)
$$

-   **object** é o seu modelo obtido pela função **lm()**.

Exemplo:

```{r}
modelo <- lm(ig~trat, data=dados) # criando modelo
anova(modelo) # anova
```

## Coeficiente de Variação (CV) experimental

O **CV(%)** é apenas a divisão do desvio padrão pela média. No caso de um experimento, usamos o desvio padrão residual, obtido pelo quadrado médio (QM) do quadro da anova.

$$
CV(\%)=\frac{\sqrt{QM\;residual}}{média \;da\;resposta}*100
$$

O QM é um nome para **variância** e, assim, o desvio padrão é apenas a sua raiz quadrada. Para experimentos no campo da agronomia, a precisão experiemental pode ser classificada conforme o CV(%) (Gomes, 1987):

| Coeficiente de Variação - CV (%) | Precisão experimental |
|:--------------------------------:|:---------------------:|
|            CV \< 10%             |         Alta          |
|         10 \< CV \< 20%          |         Média         |
|         20 \< CV \< 30%          |         Baixa         |
|            CV \> 30%             |      Muito baixa      |

## Exemplos no R - CV experimental

Podemos obter o quadrado médio residual diretamente do quadro da anova ou calcularmos:

```{r}
soma_de_quadrados_residual <- sum(residuals(modelo)^2) # Soma de quadrados
quadrado_medio_residual <- soma_de_quadrados_residual/df.residual(modelo) # Quadrado médio
desvio_padrao_residual <- sqrt(quadrado_medio_residual) # desvio padrão
CV <- desvio_padrao_residual/mean(dados$ig)*100 # CV(%)
CV # mostrando o CV
```

# Comparações múltiplas

## Pacote Emmeans

$$emmeans(object, specs, type, … )$$

-   O *object* é o seu modelo

-   *specs* é o argumento responsável pelo desdobramento das médias:

| Número de fatores                       | simbolo | exemplo                               |
|-----------------------------|---------------|----------------------------|
| Um fator                                |         | specs = \~ tratamento                 |
| Dois fatores: fator 1 dentro do fator 2 | $$|$$   | specs = \~ tratamento1 \| tratamento2 |
| Dois fatores: todas as combinações      | $$*$$   | specs = \~ tratamento1 \* tratamento2 |

-   type: usamos type="response" quando utilizamos outra distribuição que não a normal.

## Pacote multicomp

É comum atribuirmos letras na nossa comparação de médias para facilitar a visualização delas: letras iguais/diferentes, médias iguais/diferentes. Para isso, usamos a função **cld()** (*compact letter display*) do pacote **multicomp**:

```{r, eval=FALSE}
install.packages("multicomp")
```

$$
cld(object, Letters = LETTERS, reversed = TRUE,...)
$$

-   **Object** o objeto com as médias que você obteve com a função **emmeans().**

-   **Letters** define que serão utilizadas letras e não números na comparação, ao passo que "= LETTERS", significa que serão letras maiúsculas.

-   **reversed = TRUE** ordenar as médias de forma decrescente.

## Exemplos no R - emmeans fatorial duplo em DIC

### $1^{\circ}$ Carregando dados

```{r}
library(ExpDes.pt) # carregando o pacote
dados <- ex4 # armazenando ex4 em "dados"
dados$revol <- as.factor(dados$revol) # transformando em fator
dados$esterco <- as.factor(dados$esterco) # transformando em fator
```

### $2^{\circ}$ Criando o modelo

```{r}
modelo <- lm(c~revol*esterco, data=dados) # criando modelo
```

## Exemplos no R - emmeans fatorial duplo em DIC

### $3^{\circ}$ Comparando as médias

```{r}
library(emmeans) # carregando o pacote
medias <- emmeans(modelo, specs = ~ revol|esterco) # médias
library(multcomp) # facilitar a visualização por meio das "letras"
cld(medias, Letters = LETTERS, reversed = TRUE) # mostrando as médias com as "letras"
```

## Pacote ExpDes.pt

O pacote **ExpDes.pt** engloba diversos delinementos e realiza os procedimentos automaticamente: ANOVA, testes de pressupostos e comparação de médias. Basta usar a função conforme o seu delineamento:

| Delineamento                                                     |                Função                |
|---------------------------------------------|:-------------------------:|
| Inteiramente casualizado                                         |        $dic(trat, resp,...)$         |
| Fatorial duplo inteiramente casualizado                          |  $fat2.dic(fator1, fator2, resp,…)$  |
| Fatorial duplo inteiramente casualizado com tratamento adicional | $fat2.ad.dic(fator1,fator2,repet,…)$ |
| Blocos casualizados                                              |     $dbc(trat, bloco, resp,...)$     |
| Quadrado latino                                                  |     $dql(trat, linha, coluna,…)$     |

$*$ **Nota**: se o pacote faz todas as etapas, o porque ensinar por meio de funções separadamente? A principal razão é que junto com a facilidade de utilizar um pacote, vem a dificuldade de acessar os resultados separadamente, para fins de gráficos ou análises mais complexas.

## Pacote ExpDes.pt

Cada função possui diversos argumentos; porém, alguns são básicos e se repetem entre as funções:

| Argumento   | O que é?                                                                                                   |
|--------------|----------------------------------------------------------|
| trat        | Variável tratamento.                                                                                       |
| resp        | Variável resposta.                                                                                         |
| quali       | Se os tratamentos são (TRUE) ou não (FALSE) qualitativo.                                                   |
| mcomp       | Teste de comparação de médias (Tukey, Scott-Knott, Duncan...).                                             |
| fac.names   | Mostrar os nomes dos tratamentos durante a análise.                                                        |
| sigT e sigF | Nível de significancia do teste T (comparação de médias) e F (ANOVA).                                      |
| unfold      | Se não deve realizar compração de médias (0), se deve desdobrar só efeitos simples (1) ou a interação (2). |

Consulte **?ExpDes.pt** para ver todas as funções e os demais argumentos da função escolhida.

## Exemplos no R - ExpDes.pt DIC Fatorial duplo

```{r}
library(ExpDes.pt) # carregando pacote
fat2.dic(dados$revol, dados$esterco, dados$c, fac.names = c("revol", "esterco")) # fazendo a análise completa
```

## Contrastes ortogonais

Imagine um experimento em que temos cinco níveis: solo sem adubção, com adubação orgânica 1 e 2; e com adubação química 1 e 2. Além de compararmos as médias duas a duas, poderiamos querer algumas comparações interessantes como:

-   Adubar com alguma coisa foi melhor que sem aubação?

-   A adubação orgânica foi melhor que a adubação química?

![](images/contrastes.png){width="549"}

Assim, contrastes ortogonais são uma forma de compararmos **grupos** de médias.

## Contrastes ortogonais

Os contrastes são ortogonais quando você divide os níveis em grupos e o próximo contraste é a divisão do grupo anterior em um novo subgrupo:

![](images/contrastes2.png){width="751"}

Logo, fica evidente que existem diversas combinações e que o número de contrastes será sempre 1 - o número de níveis.

Porém, uma dúvida pode surgir: **como, de fato, comparamos uma média com outras quatro?** A solução é multiplicar a primeira média por quatro e comparar com as outras médias somadas.

## Contrastes ortogonais

Para definir os contrastes e os coeficientes que multiplicarão as médias, pode-se usar a função do pacote **emmeans**:

$$
contrast(object, method,...)
$$

-   **object** é o objeto criado com a função **emmeans()**.

-   **method** define os contrastes. Para isso, deve-se criar um lista com cada contraste, ou seja, especificando o valor dos coeficientes, por meio da função **list()**:

    -   Por exemplo, o primeiro nível $vs$ os três últimos: **method=list(c(3,-1,-1,-1))**

## Exemplos no R - Contrastes ortogonais

### $1^{\circ}$ Carregando dados e criando o modelo

```{r}
library(ExpDes.pt) # carregando pacote com dados de exemplo (ex1)
dados <- ex1 # armazenando ex1 em "dados"
dados$trat <- as.factor(dados$trat) # transformando "trat" em fator
modelo <- lm(ig~trat, data=dados) # criando modelo
```

### $2^{\circ}$ Estimando as médias

```{r}
library(emmeans) # carregando pacote emmeans
medias <- emmeans(modelo, specs = ~trat) # obtendo as médias
medias # mostrando as médias
```

## Exemplos no R - Contrastes ortogonais

### $3^{\circ}$ Criando contrastes

Nível 0 $vs$ níveis 5, 10, 15; nível 5 $vs$ níveis 10 e 15; nível 10 $vs$ nível 15.

```{r}
contrast(medias, method = list(c(3, -1, -1,-1), c(0,2,-1,-1), c(0,0,1,-1)))
```

# Modelos Lineares Generalizados (GLM)

## O que são?

Alguns dados claramente pertencem a outra distribuição que não a normal: dados de contagem - Poisson (ex., número de plantas daninhas), dados binomiais (ex., germinação ou não germinação), entre outras.

$*$ **Cuidado com a terminologia!** Distribuição é a distribuição de probabilidade que é simplesmente a probabilidade de obtermos um determinado valor de algo que medimos, como ocorre em nossas repetições. Existem algumas distribuições teóricas que utilizamos, já que mais fácil (e barato) do que realizarmos milhares de repetições.

Porém, diferente do modelo linear, em que a média do dados normais é obtida por uma **combinação linear entre os coeficientes** - coeficientes separados por uma soma por exemplo:

$$
\mu_j=\beta_1*Nível_1+\beta_2*Nível_2... 
$$

O mesmo não ocorre quando usamos outra distribuição. Veja, como é média na distribuição de Poisson (representada pela letra grega lambda):

$$
\lambda_j=e^{\beta_1*Nível_1+\beta_2*Nível_2...}
$$

## O que são?

Como é dificil estimar a média usando coeficientes que não têm uma combinação linear, a solução encontrada foi **transformar a média dessa distribuição** para que os coeficientes sejam lineares:

$$
g(\lambda_j)=\beta_1*Nível_1+\beta_2*Nível_2...
$$

O $g$ é chamado de função de ligação e ela varia de acordo com a distribuição escolhida.

Veja como é transformada a média na distribuição de Poisson, para que tenhamos uma combinação linear entre os coeficientes:

![](images/glm.jpg){width="525"}

Assim, esse método é uma *generalização dos modelos lineares* (GLM), pois obtemos um modelo linear a partir de qualquer distribuição pertencente à familia exponencial (ex., normal, binomial, poisson...).

## Por que?

É uma opção a mais para quando temos dados não normais, pois o que geralmente ocorre é:

1.  Transformar os dados.
2.  Utilizar uma estatística não paramétrica.
3.  Ignorar a não normalidade e prosseguir com a análise.

Uma quarta alternativa é testar alguma outra distribuição, a qual não exige os pressupostos da normalidade e/ou que seja mais bem ajustada aos dados, **mesmo que esses atendam a normalidade**.

## Algumas distribuições - Normal

A distribuição normal é a mais comum e é utilizada para dados contínuos ou não. Se utilizarmos a distribuição normal em um glm, o resultado será o mesmo que pelo lm (modelo linear).

```{r,echo=F, out.width="60%"}
library(ggplot2); library(ggpubr); library(cowplot)
set.seed(49)
a <- data.frame(resposta=rnorm(100,10,3),tratamento="a")
b <- data.frame(resposta=rnorm(100,20,3),tratamento="b")
c <- data.frame(resposta=rnorm(100,30,3),tratamento="c")
dados_normal <- rbind(a,b,c)

p <- ggplot(dados_normal, aes(tratamento, resposta, colour=tratamento))+ geom_jitter()+theme_bw()
dens <- ggdensity(dados_normal, "resposta", fill = "tratamento") +rotate()

p <- p + rremove("legend")
dens <- dens + clean_theme() + rremove("legend")
plot_grid(p, dens, ncol = 2, align = "h", 
          rel_widths = c(2, 1), rel_heights = c(1, 1))
```

## Algumas distribuições - Poisson

Utilizada para **dados de contagem** (ex., número de ovos de inseto, surgimento de plantas daninhas).

```{r, echo=F, out.width="55%"}
set.seed(30)
a <- data.frame(resposta=rpois(100,2),tratamento="a")
b <- data.frame(resposta=rpois(100,15),tratamento="b")
c <- data.frame(resposta=rpois(100,35),tratamento="c")
dados_pois <- rbind(a,b,c)

p <- ggplot(dados_pois, aes(tratamento, resposta, colour=tratamento))+ geom_jitter()+theme_bw()

dens <- ggplot(dados_pois, aes(resposta, fill=tratamento))+
  geom_bar(alpha=0.8)+
  rotate()+
  theme_classic()+
  rremove("legend")

p <- p + rremove("legend")
dens <- dens + clean_theme() + rremove("legend")
plot_grid(p, dens, ncol = 2, align = "h", 
          rel_widths = c(2, 1), rel_heights = c(1, 1))

```

**Cuidado!** Essa distribuição exige que a variância dos dados seja igual a média. Se a variância for maior, ocorre o que é chamado de superdisperção dos dados e isso sempre deve ser testado.

## Algumas distribuições- Binomial

Usada para dados com **resposta mutuamente exclusiva**, ou seja, sucesso ou fracasso (ex., germinação de sementes, morte de insetos).

```{r, echo=F, out.width="60%"}
set.seed(49)
a <- data.frame(resposta=rbinom(100,15,0.1),tratamento="a")
b <- data.frame(resposta=rbinom(100,15,0.5),tratamento="b")
c <- data.frame(resposta=rbinom(100,15,0.9),tratamento="c")
dados_bin <- rbind(a,b,c)

# ggplot
p <- ggplot(dados_bin, aes(tratamento, resposta, colour=tratamento))+ geom_jitter()+theme_bw()

# barplot
dens <- ggplot(dados_bin, aes(resposta, fill=tratamento))+
  geom_bar(alpha=0.8)+
  rotate()+
  theme_classic()+
  rremove("legend")

p <- p + rremove("legend")
dens <- dens + clean_theme() + rremove("legend")
plot_grid(p, dens, ncol = 2, align = "h", 
          rel_widths = c(2, 1), rel_heights = c(1, 1))
```

## Algumas distribuições - Gamma

Usada em dados **contínuos e positivos**, como em dados climatológicos (ex., a precipitação acumulada).

```{r, echo=F, out.width="60%"}
set.seed(5)
a <- data.frame(resposta=rgamma(100,3,1),tratamento="a")
b <- data.frame(resposta=rgamma(100,10,1),tratamento="b")
c <- data.frame(resposta=rgamma(100,20,1),tratamento="c")
dados_gam <- rbind(a,b,c)

p <- ggplot(dados_gam, aes(tratamento, resposta, colour=tratamento))+ geom_jitter()+theme_bw()
dens <- ggdensity(dados_gam, "resposta", fill = "tratamento") +rotate()

p <- p + rremove("legend")
dens <- dens + clean_theme() + rremove("legend")
plot_grid(p, dens, ncol = 2, align = "h", 
          rel_widths = c(2, 1), rel_heights = c(1, 1))
```

-   **Outras distribuições:** <https://en.wikipedia.org/wiki/Exponential_family>

## GLM no R

Semelhante ao **lm()**, a função para criar o modelo é:

$$
glm(formula, family, data,...) 
$$

-   **fórmula** é o modelo conforme o delineamento escolhido.

-   **family** determina a distribuição:

    -   Binomial: **="binomial"**

    -   Poisson: **="poisson"**

    -   Gamma: **="gamma"**, entre outras.

-   **data** são seus dados.

## GLM no R

A "ANOVA de um GLM" se chama Análise de Deviance e é usada a partir da mesma função.

$$
anova(object,test,...)
$$

-   **object** é o modelo criado com a função **glm()**.

-   **test** especifica qual teste devemos aplicar, o qual varia de acordo com a distribuição escolhida:

| Distribuição       | Teste    | Como fica                   |
|--------------------|----------|-----------------------------|
| Normal e gamma     | F        | anova(modelo, test="F")     |
| Binomial e poisson | $\chi^2$ | anova(modelo, test="Chisq") |

## Exemplos no R - GLM Binomial

### $1^{\circ}$ Carregando os dados

Experimento avaliando germinação de oito repetições de 25 sementes armazenadas por quatro meses em dois tipos de embalagem (0.1mm e 0.2mm).

```{r}
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/germinacao") # obter os dados de exemplo no repositório online
str(dados) # mostrar como são os dados
```

## Exemplos no R - GLM Binomial

### $2^{\circ}$ Criando a variável resposta

Criando uma nova variável com duas colunas, uma com a germinação e a outra com as sementes que não germinaram (25 sementes - o total germinado).

```{r}
resposta <- cbind(dados$germ, 25-dados$germ) # juntar colunas (cbind) com as sementes que germinaram e não germinaram
head(resposta) # mostrar o começo (head) dos dados
```

## Exemplos no R - GLM Binomial

### $3^{\circ}$ Criando o modelo e realizando a análise de deviance

```{r}
modelo <- glm(resposta ~ armazenamento*embalagem, data=dados, family="binomial") # criar modelo binomial
anova(modelo, test="Chisq") # "anova" do modelo
```

## Exemplos no R - GLM Binomial

### $4^{\circ}$ Comparação de médias

```{r}
library(emmeans) # carregar pacote
médias <- emmeans(modelo, specs=~armazenamento|embalagem, type="response") # estimar as médias
library(multcomp) # carregar pacote das "letras"
cld(médias, Letters=LETTERS, reverse=TRUE) # mostrar as médias com as "letras"
```

## Exemplos no R - GLM Poisson

### $1^{\circ}$ Carregando os dados

Experimento avaliando o número de plântulas emergidas de três lotes de sementes, beneficiadas em peneiras com quatro crivos diferentes (testemunha, 0,84mm, 1mm, 1,18mm).

```{r}
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/contagem%20plantulas") # carregar dados do repositório online
str(dados) # mostrar como são os dados
```

### $2^{\circ}$ Criando o modelo

```{r}
modelo <- glm(plantulas~lote*peneira, data=dados, family="poisson") # criar modelo Poisson
```

## Exemplos no R - GLM Poisson

### $3^{\circ}$ Checando o pressuposto

```{r}
library(AER) # carregar pacote
dispersiontest(modelo) # testar superdispersão
```

## Exemplos no R - GLM Poisson

### $4^{\circ}$ Análise de deviance

```{r}
anova(modelo, test="Chisq") # criar modelo
```

## Exemplos no R - GLM Poisson

### $5^{\circ}$ Comparação de médias

```{r}
library(emmeans) # carregar pacote
médias <- emmeans(modelo, specs=~peneira|lote, type="response") # estimar as médias
library(multcomp) # carregar pacote com as "letras"
cld(médias, Letters=LETTERS, reverse=TRUE) # mostrar as médias com as "letras"
```

# Comparação de modelos

## Critério de Akaike (AIC)

Existem várias formas de comparar modelos, o AIC é um dos mais populares:

![](images/AIC.png){width="598"}

A fórmula do AIC é simples, nela contém uma parte relativa ao número de parâmetros ($k$) e outra parte relativa ao ajuste, por meio do valor máximo do chamado *likelihood* ou verossemilhança ($L$).

Reparem que de acordo com a fórmula, quanto mais parâmetros (parte positiva) e/ou quanto menor o ajuste (parte negativa), maior o valor de AIC. Logo, **quanto menor o valor de AIC melhor o modelo**.

## Exemplos no R - AIC

### $1^{\circ}$ Carregando dados

Usaremos os dados do experimento referente ao número de plântulas emergidas.

```{r}
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/contagem%20plantulas") # carregando dados do respositório online
str(dados) # mostrando como são os dados
```

## Exemplos no R - AIC

### $2^{\circ}$ Criando modelo normal e checando os pressupostos

```{r}
modelo_normal <- lm(plantulas~lote*peneira, data=dados) # criando modelo normal
erros <- residuals(modelo_normal) # calculando os erros (resíduos)
shapiro.test(erros) # testando a normalidade do resíduo
library(car) # carregando pacote
leveneTest(erros~lote*peneira, data=dados) # testando a homogenidade da variância dos residuos 
durbinWatsonTest(modelo_normal) # testando a independência dos resíduos
```

## Exemplos no R - AIC

### $3^{\circ}$ Criando modelo com distribuição de Poisson

```{r}
modelo_poisson <- glm(plantulas~lote*peneira, data=dados, family="poisson") # criando modelo Poisson
```

### $4^{\circ}$ Criando modelo com distribuição binomial negativa

```{r}
library(MASS) # carregando pacote
modelo_binomial_negativa <- glm.nb(plantulas~lote*peneira, data=dados) # criando modelo binomial negativa
```

## Exemplos no R - AIC

### $5^{\circ}$ Comparando os modelos

$$
AIC(object,...)
$$

```{r}
AIC(modelo_normal, modelo_poisson, modelo_binomial_negativa) # comparando os modelos
```

## O que realmente muda?

Se os dados são normais, por que testar outros ajustes?

```{r}
library(emmeans) # carregando pacote
media_normal <- emmeans(modelo_normal, specs=~peneira|lote) # estimando as médias modelo normal
media_poisson <- emmeans(modelo_poisson, specs=~peneira|lote, type="response") # estimando as médias modelo Poisson
library(multcomp) # carregando pacote com as "letras"
letras_normal <- cld(media_normal, Letters = LETTERS, reversed = T) # média com as "letras"
letras_poisson <- cld(media_poisson, Letters = LETTERS, reversed = T, type="response") # médias com as "letras"
cbind(letras_normal, letras_poisson)[,c(1,2,8,16)] # colocando lado a lado as respostas

```

## O que realmente muda?

```{r}
library(ggplot2) # carregando ggplot2
library(gridExtra) # carregando pacote para criar painél
g1 <- ggplot(as.data.frame(media_normal))+ # dados
aes(y=emmean, x=lote, fill=peneira)+ # atributos
  geom_col(position="dodge2") + # gráfico de colunas
  geom_errorbar(aes(ymin = lower.CL , ymax = upper.CL),
                width = 0.2,
                position = position_dodge(width = 0.9)) + # barras de erro 
  theme_classic()+  theme(legend.position="top") + ggtitle("Normal") # temas

g2 <- ggplot(as.data.frame(media_poisson))+ # dados
  aes(y=rate, x=lote, fill=peneira)+ # atributos
  geom_col(position="dodge2") + # gráfico de colunas
  geom_errorbar(aes(ymin = asymp.LCL , ymax = asymp.UCL), 
                width = 0.2,
                position = position_dodge(width = 0.9)) + # barras de erro 
theme_classic() +  theme(legend.position="top") + ggtitle("Poisson") # temas
grid.arrange(g1, g2, ncol=2)

```

## Referências

-   Bussab, W. O.; Morettin, P. A. **Estatística Básica (9 ed.)**. Saraiva, 2017, p. 553.

-   Pimentel Gomes, F. **Curso de Estatística Experimental (12 ed.)**. Piracicaba, 1987, p. 467.

-   Cordeiro, G. M.; Demétrio, C. G. **Modelos lineares generalizados e extensões**. Piracicaba, 2008, p. 400.

-   Zeviani, W. M. **Manual de Planejamento e Análise de Experimentos com R**.

    -   <http://leg.ufpr.br/~walmes/mpaer/index.html>

-   Olivoto, T.; Sari, B. G. **Software R para avaliação de dados experimentais: Um foco em experimentos agronômicos (vol. 2)**.

    -   <https://tiagoolivoto.github.io/e-bookr/index.html>

-   Michelon, T. B.; Taconeli, C. A.; Vieira, E. S. N.; Panobianco, M. Eucalyptus cloeziana seed count data: a comparative analysis of statistical models. **Ciência e Agrotecnologia**, v. 43, 2019.

## Códigos

```{r, eval=FALSE}
### Delineamento
## DIC fatorial simples
library(ExpDes.pt) # carregar o pacote que tem os dados de exemplo (ex1)
dados <- ex1 # carregar ex1 armazenar em "dados"
dados$trat <- as.factor(dados$trat) # Entender que "trat" é um fator e não números
head(dados) # mostrar só o começo (head) dados
lm(ig~trat, data = dados) # criando modelo
## DIC fatorial duplo
library(ExpDes.pt) # carregar o pacote que tem os dados de exemplo (ex4)
dados <- ex4 # armazenar ex4 em "dados"
dados$revol <- as.factor(dados$revol) # entender que "trat" é um fator e não números
dados # mostrar os dados
lm(c~revol*esterco, data=dados) # criando modelo
## DBC fatorial simples
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/Pimentel%20gomes%20DBC") # lendo dados do repositório online
head(dados) # mostrando o começo dos dados
lm(producao~bloco+variedade, data=dados) # modelo DBC

### ANOVA
## Teste de pressupostos
library(ExpDes.pt) # carregar pacote
dados <- ex1 # armazenar ex1 em "dados"
dados$trat <- as.factor(dados$trat) # transformar 
modelo <- lm(ig~trat, data=dados) # entender que "trat" é um fator e não números
erros <- residuals(modelo) # função "residuals" para obter os erros
shapiro.test(erros) # teste de Shapiro-Wilk
library(car) # pacote com a função
leveneTest(erros~trat, data=dados) # Levene
bartlett.test(erros~trat, data=dados) # teste de Bartlett
library(car) # pacote com a função
durbinWatsonTest(modelo) # teste de Durbin-Watson
## Análise gráfica
modelo <- lm(ig~trat, data=dados) # criando modelo
par(mfrow=c(2,2)) # plotar os quatro gráficos na mesma tela
plot(modelo) # gerar gráficos 
## Box-Cox
library(ExpDes.pt) # carrear pacote
dados <- ex1 # armazenar ex1 em "dados"
dados$trat <- as.factor(dados$trat) # entender que "trat" é um fator e não números
library(MASS) # carregando o pacote com a função "boxcox"
bc <- boxcox(dados$ig~dados$trat) # testando os lambdas e identificando o melhor
maior_likelihood <- which.max(bc$y) # maior valor do "log likelihood"
lambda <- bc$x[maior_likelihood] # valor do lambda que corresponde ao maior "log likelihood"
lambda # valor de lambda
transformacao <- function(y, lambda) {
  if (lambda == 0L) { # se o lambda for igual a 0, log(y)
    log(y)
  } else { # se for diferente de 0, (y^lambda)-1/lambda
    ((y^lambda) - 1) / lambda
  }
}
dados_transformados <- transformacao(dados$ig, 0.0202) # transformando
head(cbind(dados$ig, dados_transformados)) # mostrando os dados lado a lado (cbind)
lm(dados_transformados~trat, data=dados) # modelo com os dados transformados
##ANOVA
modelo <- lm(ig~trat, data=dados) # criando modelo
anova(modelo) # anova

### Comparações múltiplas
## Pacote Emmeans e multicomp
library(ExpDes.pt) # carregando o pacote
dados <- ex4 # armazenando ex4 em "dados"
dados$revol <- as.factor(dados$revol) # transformando em fator
dados$esterco <- as.factor(dados$esterco) # transformando em fator
modelo <- lm(c~revol*esterco, data=dados) # criando modelo
library(emmeans) # carregando o pacote
medias <- emmeans(modelo, specs = ~ revol|esterco) # médias
library(multcomp) # facilitar a visualização por meio das "letras"
cld(medias, Letters = LETTERS, reversed = TRUE) # mostrando as médias com as "letras"
## Pacote ExpDes.pt
{r}
library(ExpDes.pt) # carregando pacote
fat2.dic(dados$revol, dados$esterco, dados$c, fac.names = c("revol", "esterco")) # fazendo a análise completa
## Contrastes ortogonais
library(ExpDes.pt) # carregando pacote com dados de exemplo (ex1)
dados <- ex1 # armazenando ex1 em "dados"
dados$trat <- as.factor(dados$trat) # transformando "trat" em fator
modelo <- lm(ig~trat, data=dados) # criando modelo
library(emmeans) # carregando pacote emmeans
medias <- emmeans(modelo, specs = ~trat) # obtendo as médias
medias # mostrando as médias
contrast(medias, method = list(c(3, -1, -1,-1), c(0,2,-1,-1), c(0,0,1,-1)))

### GLM
## Binomial
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/germinacao") # obter os dados de exemplo no repositório online
str(dados) # mostrar como são os dados
resposta <- cbind(dados$germ, 25-dados$germ) # juntar colunas (cbind) com as sementes que germinaram e não germinaram
head(resposta) # mostrar o começo (head) dos dados
modelo <- glm(resposta ~ armazenamento*embalagem, data=dados, family="binomial") # criar modelo binomial
anova(modelo, test="Chisq") # "anova" do modelo
library(emmeans) # carregar pacote
médias <- emmeans(modelo, specs=~armazenamento|embalagem, type="response") # estimar as médias
library(multcomp) # carregar pacote das "letras"
cld(médias, Letters=LETTERS, reverse=TRUE) # mostrar as médias com as "letras"
## Poisson
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/contagem%20plantulas") # carregar dados do repositório online
str(dados) # mostrar como são os dados
modelo <- glm(plantulas~lote*peneira, data=dados, family="poisson") # criar modelo Poisson
library(AER) # carregar pacote
dispersiontest(modelo) # testar superdispersão
anova(modelo, test="Chisq") # criar modelo
library(emmeans) # carregar pacote
médias <- emmeans(modelo, specs=~peneira|lote, type="response") # estimar as médias
library(multcomp) # carregar pacote com as "letras"
cld(médias, Letters=LETTERS, reverse=TRUE) # mostrar as médias com as "letras"

### Comparação de modelos
## AIC
dados <- dget("https://raw.githubusercontent.com/thomasbrunomichelon/data/main/contagem%20plantulas") # carregando dados do respositório online
str(dados) # mostrando como são os dados
modelo_normal <- lm(plantulas~lote*peneira, data=dados) # criando modelo normal
erros <- residuals(modelo_normal) # calculando os erros (resíduos)
shapiro.test(erros) # testando a normalidade do resíduo
library(car) # carregando pacote
leveneTest(erros~lote*peneira, data=dados) # testando a homogenidade da variância dos residuos 
durbinWatsonTest(modelo_normal) # testando a independência dos resíduos
modelo_poisson <- glm(plantulas~lote*peneira, data=dados, family="poisson") # criando modelo Poisson
library(MASS) # carregando pacote
modelo_binomial_negativa <- glm.nb(plantulas~lote*peneira, data=dados) # criando modelo binomial negativa
AIC(modelo_normal, modelo_poisson, modelo_binomial_negativa) # comparando os modelos
## O que realmente muda ?
library(emmeans) # carregando pacote
media_normal <- emmeans(modelo_normal, specs=~lote|peneira) # estimando as médias modelo normal
media_poisson <- emmeans(modelo_poisson, specs=~lote|peneira) # estimando as médias modelo Poisson
library(multcomp) # carregando pacote com as "letras"
letras_normal <- cld(media_normal, Letters = LETTERS, reversed = T) # média com as "letras"
letras_poisson <- cld(media_poisson, Letters = LETTERS, reversed = T, type="response") # médias com as "letras"
cbind(letras_normal, letras_poisson)[,c(1,2,8,16)] # colocando lado a lado as respostas
library(ggplot2) # carregando ggplot2
library(gridExtra) # carregando pacote para criar painél
g1 <- ggplot(as.data.frame(media_normal))+ # dados
aes(y=emmean, x=peneira, fill=lote)+ # atributos
  geom_col(position="dodge2") + # gráfico de colunas
  geom_errorbar(aes(ymin = lower.CL , ymax = upper.CL),
                width = 0.2,
                position = position_dodge(width = 0.9)) + # barras de erro 
  theme_classic()+  theme(legend.position="top") + ggtitle("Normal") # temas

g2 <- ggplot(as.data.frame(media_poisson))+ # dados
  aes(y=rate, x=peneira, fill=lote)+ # atributos
  geom_col(position="dodge2") + # gráfico de colunas
  geom_errorbar(aes(ymin = asymp.LCL , ymax = asymp.UCL), 
                width = 0.2,
                position = position_dodge(width = 0.9)) + # barras de erro 
theme_classic() +  theme(legend.position="top") + ggtitle("Poisson") # temas
grid.arrange(g1, g2, ncol=2)
```
